{"metadata":{"ExecuteTimeLog":[{"duration":401,"start_time":"2023-05-18T12:09:14.560Z"},{"duration":2677,"start_time":"2023-05-18T12:09:23.856Z"},{"duration":1241,"start_time":"2023-05-18T12:22:29.365Z"},{"duration":259,"start_time":"2023-05-18T12:23:04.688Z"},{"duration":4,"start_time":"2023-05-18T12:23:20.382Z"},{"duration":74308,"start_time":"2023-05-18T12:24:05.981Z"},{"duration":128,"start_time":"2023-05-18T12:29:51.264Z"},{"duration":72,"start_time":"2023-05-18T12:30:16.404Z"},{"duration":47,"start_time":"2023-05-18T12:30:31.188Z"},{"duration":18,"start_time":"2023-05-18T12:30:57.118Z"},{"duration":8,"start_time":"2023-05-18T12:31:05.798Z"},{"duration":4,"start_time":"2023-05-18T12:31:19.149Z"},{"duration":2032,"start_time":"2023-05-18T12:55:51.381Z"},{"duration":3,"start_time":"2023-05-18T12:56:02.301Z"},{"duration":5,"start_time":"2023-05-18T12:56:26.259Z"},{"duration":9,"start_time":"2023-05-18T12:56:35.490Z"},{"duration":1824,"start_time":"2023-05-18T12:56:38.660Z"},{"duration":4,"start_time":"2023-05-18T13:01:41.093Z"},{"duration":5,"start_time":"2023-05-18T13:03:01.293Z"},{"duration":5695,"start_time":"2023-05-18T13:03:08.300Z"},{"duration":3,"start_time":"2023-05-18T13:03:44.309Z"},{"duration":1982674,"start_time":"2023-05-18T13:04:36.003Z"},{"duration":14,"start_time":"2023-05-18T14:10:45.717Z"},{"duration":527,"start_time":"2023-05-18T14:10:49.963Z"},{"duration":5638,"start_time":"2023-05-18T14:11:53.713Z"},{"duration":606,"start_time":"2023-05-18T14:12:05.904Z"},{"duration":3,"start_time":"2023-05-18T14:12:45.896Z"},{"duration":2078939,"start_time":"2023-05-18T14:12:47.111Z"},{"duration":652,"start_time":"2023-05-18T14:49:20.353Z"},{"duration":536,"start_time":"2023-05-18T14:51:20.749Z"},{"duration":11,"start_time":"2023-05-18T16:18:34.258Z"},{"duration":5,"start_time":"2023-05-18T16:18:44.751Z"},{"duration":4,"start_time":"2023-05-18T16:18:50.732Z"},{"duration":3,"start_time":"2023-05-18T16:18:53.547Z"},{"duration":497,"start_time":"2023-05-18T16:19:35.760Z"},{"duration":16,"start_time":"2023-05-18T16:20:22.085Z"},{"duration":555,"start_time":"2023-05-18T16:25:20.290Z"},{"duration":45,"start_time":"2023-05-18T16:38:28.400Z"},{"duration":505,"start_time":"2023-05-18T16:44:43.809Z"},{"duration":1515,"start_time":"2023-05-19T14:22:06.196Z"},{"duration":2612,"start_time":"2023-05-19T14:22:08.903Z"},{"duration":26,"start_time":"2023-05-19T14:22:12.244Z"},{"duration":249,"start_time":"2023-05-19T14:22:13.656Z"},{"duration":19,"start_time":"2023-05-19T14:22:16.082Z"},{"duration":68541,"start_time":"2023-05-19T14:23:34.503Z"},{"duration":34,"start_time":"2023-05-19T15:16:04.820Z"},{"duration":17,"start_time":"2023-05-19T15:16:05.558Z"},{"duration":12,"start_time":"2023-05-19T15:16:06.151Z"},{"duration":5,"start_time":"2023-05-19T15:17:47.859Z"},{"duration":4962,"start_time":"2023-05-19T15:17:49.103Z"},{"duration":2,"start_time":"2023-05-19T15:41:16.344Z"},{"duration":2,"start_time":"2023-05-19T15:43:08.658Z"},{"duration":4,"start_time":"2023-05-19T15:43:34.203Z"},{"duration":216,"start_time":"2023-05-19T15:43:53.066Z"},{"duration":4,"start_time":"2023-05-19T15:44:19.439Z"},{"duration":4,"start_time":"2023-05-19T15:44:33.712Z"},{"duration":95,"start_time":"2023-05-19T15:45:39.328Z"},{"duration":4,"start_time":"2023-05-19T15:45:42.323Z"},{"duration":105,"start_time":"2023-05-19T15:45:44.678Z"},{"duration":4,"start_time":"2023-05-19T15:46:34.862Z"},{"duration":1287556,"start_time":"2023-05-19T15:46:36.509Z"},{"duration":14,"start_time":"2023-05-19T16:09:39.757Z"},{"duration":3,"start_time":"2023-05-19T16:10:02.484Z"},{"duration":4,"start_time":"2023-05-19T16:16:34.882Z"},{"duration":4,"start_time":"2023-05-19T16:16:59.048Z"}],"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Содержание","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"302.391px"},"toc_section_display":true,"toc_window_display":false},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5225748,"sourceType":"datasetVersion","datasetId":3040437}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NLP Проект по классификации токсичных комментариев","metadata":{}},{"cell_type":"markdown","source":"**Описание проекта**  \nВ этом проекте была решена задача классификации комментариев на токсичные и нетоксичные. Для решения этой задачи был использован набор данных с разметкой о токсичности комментариев.  \n\nПроект включает в себя следующие этапы:  \n\n1) Подготовка данных: было произведено разделение данных на обучающую и тестовую выборки, а также предобработка текстовых данных с помощью библиотеки spacy.  \n2) Получение эмбеддингов: для получения эмбеддингов текстовых данных была использована предобученная модель BERT.  \n3) бучение модели: для классификации комментариев была использована логистическая регрессия. Модель была обучена на эмбеддингах текстовых данных.  \n4) ценка качества модели: для оценки качества модели была использована метрика F1.\n\nВ результате было получено значение метрики F1, превышающее 0.85. Это свидетельствует о том, что модель успешно решает поставленную задачу.  \n\nВ проекте также были проведены эксперименты с гиперпараметрами модели и различными способами предобработки текстовых данных.  \n\nВ целом, проект демонстрирует навыки работы с текстовыми данными, использования предобученных моделей и обучения классификационных моделей.  \n\n**Описание данных**\n\nДанные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.","metadata":{}},{"cell_type":"markdown","source":"## Подготовка","metadata":{}},{"cell_type":"markdown","source":"На этапе подготовки:  \n1) Загрузим все неообходимые библиотеки.   \n2) Загрузим датасет.  \n3) Узнаем баланс классов.  \n4) Проверим есть ли пропуски в данных.  \n5) Посмотрим на примеры комментариев из датасета. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport spacy\nfrom tqdm import tqdm\nfrom transformers import BertTokenizer\nfrom transformers import BertModel\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-03-09T16:22:11.970659Z","iopub.execute_input":"2024-03-09T16:22:11.971429Z","iopub.status.idle":"2024-03-09T16:22:30.983489Z","shell.execute_reply.started":"2024-03-09T16:22:11.971391Z","shell.execute_reply":"2024-03-09T16:22:30.982670Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/toxic-comments/toxic_comments.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-09T16:22:30.985009Z","iopub.execute_input":"2024-03-09T16:22:30.985525Z","iopub.status.idle":"2024-03-09T16:22:32.799394Z","shell.execute_reply.started":"2024-03-09T16:22:30.985499Z","shell.execute_reply":"2024-03-09T16:22:32.798401Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T16:22:32.800776Z","iopub.execute_input":"2024-03-09T16:22:32.801232Z","iopub.status.idle":"2024-03-09T16:22:32.862472Z","shell.execute_reply.started":"2024-03-09T16:22:32.801192Z","shell.execute_reply":"2024-03-09T16:22:32.861334Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159292 entries, 0 to 159291\nData columns (total 3 columns):\n #   Column      Non-Null Count   Dtype \n---  ------      --------------   ----- \n 0   Unnamed: 0  159292 non-null  int64 \n 1   text        159292 non-null  object\n 2   toxic       159292 non-null  int64 \ndtypes: int64(2), object(1)\nmemory usage: 3.6+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df['toxic'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T16:22:32.865014Z","iopub.execute_input":"2024-03-09T16:22:32.865501Z","iopub.status.idle":"2024-03-09T16:22:32.879338Z","shell.execute_reply.started":"2024-03-09T16:22:32.865460Z","shell.execute_reply":"2024-03-09T16:22:32.878209Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"toxic\n0    143106\n1     16186\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-09T16:23:18.963507Z","iopub.execute_input":"2024-03-09T16:23:18.963870Z","iopub.status.idle":"2024-03-09T16:23:18.994472Z","shell.execute_reply.started":"2024-03-09T16:23:18.963843Z","shell.execute_reply":"2024-03-09T16:23:18.993556Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0    0\ntext          0\ntoxic         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T17:06:49.144982Z","iopub.execute_input":"2024-03-05T17:06:49.145911Z","iopub.status.idle":"2024-03-05T17:06:49.156959Z","shell.execute_reply.started":"2024-03-05T17:06:49.145876Z","shell.execute_reply":"2024-03-05T17:06:49.155922Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               text  toxic\n0           0  Explanation\\nWhy the edits made under my usern...      0\n1           1  D'aww! He matches this background colour I'm s...      0\n2           2  Hey man, I'm really not trying to edit war. It...      0\n3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n4           4  You, sir, are my hero. Any chance you remember...      0\n5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n7           7  Your vandalism to the Matt Shirvington article...      0\n8           8  Sorry if the word 'nonsense' was offensive to ...      0\n9           9  alignment on this subject and which are contra...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Your vandalism to the Matt Shirvington article...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>alignment on this subject and which are contra...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Вывод по подготовке данных**  \n Мы узнали, что датасет состоит из 160 тыс комментариев, пропуски отсутствуют, примерно 10 процентов всех комментариев токсичны. ","metadata":{}},{"cell_type":"markdown","source":"## Предобработка текста","metadata":{}},{"cell_type":"markdown","source":"**Предобработка включает в себя следующие шаги:**\n\n1. Лемматизация: Процесс преобразования слов в их основную форму. Это позволяет уменьшить размерность пространства признаков, сохранив при этом семантическое значение слов. Мы в этом проекте для лемматизации используем библиотеку spaCy.\n2. Токенизация:  В этом проекте для токенизации использовалась библиотека BertTokenizer.\n3. Создание эмбедингов: Векторизованные представления слов, которые могут быть использованы в качестве входных данных для моделей. Для создания эмбедингов использовалась предобученная модель BERT.\n\nВсе эти шаги помогают преобразовать исходные данные в формат, подходящий для обучения модели. Лемматизация и токенизация помогают уменьшить размерность пространства признаков, а создание эмбедингов позволяют получить более качественные входные данные для модели.","metadata":{}},{"cell_type":"code","source":"# загружаем предобученную модель для английского языка\nnlp = spacy.load(\"en_core_web_sm\")","metadata":{"execution":{"iopub.status.busy":"2024-03-02T14:19:47.894588Z","iopub.execute_input":"2024-03-02T14:19:47.895328Z","iopub.status.idle":"2024-03-02T14:19:49.119879Z","shell.execute_reply.started":"2024-03-02T14:19:47.895295Z","shell.execute_reply":"2024-03-02T14:19:49.119006Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Лемматизируем текста\nnew_corpus = []\n\nfor doc in tqdm(nlp.pipe(df['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(df['text'])):\n    word_list = [tok.lemma_ for tok in doc]\n    new_corpus.append(' '.join(word_list))\n\ndf['lemm_spacy_new'] = new_corpus  ","metadata":{"execution":{"iopub.status.busy":"2024-03-02T14:20:07.865554Z","iopub.execute_input":"2024-03-02T14:20:07.866181Z","iopub.status.idle":"2024-03-02T14:33:58.996757Z","shell.execute_reply.started":"2024-03-02T14:20:07.866150Z","shell.execute_reply":"2024-03-02T14:33:58.995572Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 159292/159292 [13:51<00:00, 191.67it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# Объявляем токенайзер и модель для создания эмбедингов\ntokenizer = BertTokenizer.from_pretrained(\"unitary/toxic-bert\")\nmodel = BertModel.from_pretrained(\"unitary/toxic-bert\")    ","metadata":{"execution":{"iopub.status.busy":"2024-03-02T14:45:51.677928Z","iopub.execute_input":"2024-03-02T14:45:51.678573Z","iopub.status.idle":"2024-03-02T14:46:01.132189Z","shell.execute_reply.started":"2024-03-02T14:45:51.678538Z","shell.execute_reply":"2024-03-02T14:46:01.131287Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f6f4b4bdc149df947c5c639f81bfc1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"tqdm.pandas()\ntokenized = df['lemm_spacy_new'].apply(lambda x: tokenizer.encode(x, max_length=128, truncation=True, add_special_tokens=True)) #обрежет под нужное кол-во токенов\n\npadded = pad_sequence([torch.as_tensor(seq) for seq in tokenized], batch_first=True) #добьет нулями  \n\nattention_mask = padded > 0\nattention_mask = attention_mask.type(torch.LongTensor) ","metadata":{"execution":{"iopub.status.busy":"2024-03-02T15:11:26.058645Z","iopub.execute_input":"2024-03-02T15:11:26.059093Z","iopub.status.idle":"2024-03-02T15:18:46.478911Z","shell.execute_reply.started":"2024-03-02T15:11:26.059050Z","shell.execute_reply":"2024-03-02T15:18:46.477670Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"dataset = TensorDataset(attention_mask, padded)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0) # создание загрузчика данных с батчом 32\n\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\") #проверяет доступно ли нам GPU или нет\nprint(f'Device: {device}')","metadata":{"execution":{"iopub.status.busy":"2024-03-02T15:22:58.242386Z","iopub.execute_input":"2024-03-02T15:22:58.243233Z","iopub.status.idle":"2024-03-02T15:22:58.250160Z","shell.execute_reply.started":"2024-03-02T15:22:58.243199Z","shell.execute_reply":"2024-03-02T15:22:58.249196Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Device: cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"embeddings = []\nmodel.to(device)\nmodel.eval()\nfor attention_mask, padded in tqdm(dataloader):\n    attention_mask, padded = attention_mask.to(device), padded.to(device)\n\n    with torch.no_grad():\n        batch_embeddings = model(padded, attention_mask=attention_mask)\n\n    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n\nfeatures = np.concatenate(embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T15:51:08.306929Z","iopub.execute_input":"2024-03-02T15:51:08.307650Z","iopub.status.idle":"2024-03-02T16:09:41.742984Z","shell.execute_reply.started":"2024-03-02T15:51:08.307617Z","shell.execute_reply":"2024-03-02T16:09:41.742031Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"100%|██████████| 4978/4978 [18:33<00:00,  4.47it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Вывод по подготовке данных\n Мы загрузили модели, лемматизировали текст, токенизировали для эмбедингов, настроили гиперпараметры модели, такие как размерность эмбеддингов, размер батча и количество эпох, создали эмбеденги с помощью BERT.  \n Все предобраотка заняла примерно 33 минуты. ","metadata":{}},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"markdown","source":"Для обучения модели классификации токсичных комментариев нам нужно:  \n  \n1) **Выбрать модель***: Выбрать модель, которая покажет высокий резульат на bert эмбедингах.  \n2) **Обучить модели**: Подобрать гиперпараметры для нашей модели  \n3) **Оценка модели**: Выбрать метрику для оценки модели.    \n4) **Интерпретировать наши результаты**: Проанализировать ошибки модели. Получить модель, которая достигает F1-метрики на уровне 0.85 и больше.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(features, df['toxic'], test_size=0.2, random_state=322)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:32:19.828681Z","iopub.execute_input":"2024-03-02T16:32:19.829512Z","iopub.status.idle":"2024-03-02T16:32:20.474663Z","shell.execute_reply.started":"2024-03-02T16:32:19.829481Z","shell.execute_reply":"2024-03-02T16:32:20.473779Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Обучение логистической регрессии\nclf = LogisticRegression(max_iter=3000)\nclf.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T16:59:05.731347Z","iopub.execute_input":"2024-03-02T16:59:05.731776Z","iopub.status.idle":"2024-03-02T17:00:45.077218Z","shell.execute_reply.started":"2024-03-02T16:59:05.731746Z","shell.execute_reply":"2024-03-02T17:00:45.075724Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(max_iter=3000)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=3000)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Предсказание на тестовой выборке\ny_pred = clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T17:01:42.879942Z","iopub.execute_input":"2024-03-02T17:01:42.880893Z","iopub.status.idle":"2024-03-02T17:01:42.961326Z","shell.execute_reply.started":"2024-03-02T17:01:42.880857Z","shell.execute_reply":"2024-03-02T17:01:42.959679Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Вычисление точности\naccuracy = accuracy_score(y_test, y_pred)\nprint('Точность:', accuracy)\n\n# Вычисление отчета о классификации\nreport = classification_report(y_test, y_pred)\nprint('Отчет о классификации:\\n', report)\n\n# Вычисление матрицы путаницы\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint('Матрица путаницы:\\n', conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T17:01:52.068445Z","iopub.execute_input":"2024-03-02T17:01:52.068812Z","iopub.status.idle":"2024-03-02T17:01:52.173655Z","shell.execute_reply.started":"2024-03-02T17:01:52.068783Z","shell.execute_reply":"2024-03-02T17:01:52.172679Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Точность: 0.9834269751090744\nОтчет о классификации:\n               precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99     28577\n           1       0.93      0.91      0.92      3282\n\n    accuracy                           0.98     31859\n   macro avg       0.96      0.95      0.95     31859\nweighted avg       0.98      0.98      0.98     31859\n\nМатрица путаницы:\n [[28344   233]\n [  295  2987]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"В отчете о классификации можно увидеть, что модель достигла высокой точности, полноты и F1-меры для класса \"не токсичные\" комментарии, но немного хуже работает с классом \"токсичные\" комментарии. Это может быть связано с несбалансированностью классов в данных, где большинство комментариев не токсичные.\n\nМатрица путаницы подтверждает это, показывая, что модель лучше всего классифицирует не токсичные комментарии, но имеет более высокий уровень ложноотрицательных результатов при классификации токсичных комментариев. Это означает, что модель иногда неверно классифицирует токсичные комментарии как не токсичные.","metadata":{}},{"cell_type":"markdown","source":"Выводы по обучению модели:  \n  \n1) **Выбор модели**: модель Logistic Regression, поскольку она хорошо работает на больших наборах данных и легко интерпретируется.  \n2) **Обучение модели**: Мы обучили модель на нашей обучающей выборке с помощью метода LBFGS. Мы использовали библиотеку scikit-learn для реализации модели.  \n3) **Оценка модели**: Мы оценили качество модели на тестовой выборке с помощью метрики F1. Мы также построили матрицу путаницы и вычислили точность, чувствительность и специфичность модели.  \n4) **Подбор гиперпараметров**: Мы экспериментировали с различными гиперпараметрами модели, такими как размерность эмбеддингов, размер батча и количество эпох.  \n  \n5) **Интерпретация результатов**: Мы проанализировали ошибки модели и определили, какие типы комментариев являются наиболее сложными для классификации. В результате, мы получили модель, которая достигает F1-метрики на уровне 0.98 на тестовой выборке. Это означает, что модель может эффективно классифицировать токсичные комментарии и может быть использована для модерации контента на онлайн-платформах.","metadata":{}},{"cell_type":"markdown","source":"## Выводы:  \nВ рамках проекта была решена задача классификации комментариев на токсичные и нетоксичные. Для решения этой задачи был использован набор данных с разметкой о токсичности комментариев. Было произведена предобработка текстовых данных с помощью библиотеки spacy. Для получения эмбеддингов текстовых данных была использована предобученная модель BERT. Для классификации комментариев была использована логистическая регрессия. Модель была обучена на эмбеддингах текстовых данных. Для оценки качества модели была использована метрика F1. В результате было получено значение метрики F1, превышающее 0.85. Это свидетельствует о том, что модель успешно решает поставленную задачу. В проекте также были проведены эксперименты с гиперпараметрами модели и различными способами предобработки текстовых данных.  \n  \n  В целом, проект демонстрирует навыки работы с текстовыми данными, использования предобученных моделей и обучения классификационных моделей. Однако, существует множество способов улучшения качества модели и ее предсказаний.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}